{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pure ML Model v1.0 - Full Dataset Training\n",
        "\n",
        "Train a pure learning model on 20 years of Gold (XAUUSD) 1h data.\n",
        "\n",
        "**Key differences from v0.1:**\n",
        "- Full dataset: 2004-2025 (~125k bars)\n",
        "- Time-based train/test split (no data leakage)\n",
        "- Pure learning: model discovers patterns, no human bias\n",
        "- Target: Price moves +0.5% within next 24 hours"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Setup - Clone repo and install dependencies\n",
        "!pip install xgboost scikit-learn pandas numpy matplotlib seaborn -q\n",
        "\n",
        "import os\n",
        "if os.path.exists('gold-ml-trading'):\n",
        "    %cd gold-ml-trading\n",
        "    !git pull\n",
        "else:\n",
        "    !git clone https://github.com/altommo/gold-ml-trading.git\n",
        "    %cd gold-ml-trading"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries loaded successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# INDICATOR FUNCTIONS (inlined to avoid import issues)\n",
        "# ============================================================\n",
        "\n",
        "def calculate_wavetrend(df, n1=10, n2=21):\n",
        "    \"\"\"Calculate WaveTrend indicator\"\"\"\n",
        "    df = df.copy()\n",
        "    ap = (df['high'] + df['low'] + df['close']) / 3\n",
        "    esa = ap.ewm(span=n1, adjust=False).mean()\n",
        "    d = (ap - esa).abs().ewm(span=n1, adjust=False).mean()\n",
        "    ci = (ap - esa) / (0.015 * d)\n",
        "    df['wt1'] = ci.ewm(span=n2, adjust=False).mean()\n",
        "    df['wt2'] = df['wt1'].rolling(4).mean()\n",
        "    return df\n",
        "\n",
        "def calculate_wolfpack(df):\n",
        "    \"\"\"Calculate Wolfpack indicator (EMA3 - EMA8)\"\"\"\n",
        "    df = df.copy()\n",
        "    df['wolfpack'] = df['close'].ewm(span=3, adjust=False).mean() - df['close'].ewm(span=8, adjust=False).mean()\n",
        "    return df\n",
        "\n",
        "def calculate_rsi(df, period=14):\n",
        "    \"\"\"Calculate RSI\"\"\"\n",
        "    df = df.copy()\n",
        "    delta = df['close'].diff()\n",
        "    gain = delta.clip(lower=0).rolling(period).mean()\n",
        "    loss = (-delta.clip(upper=0)).rolling(period).mean()\n",
        "    df['rsi'] = 100 - (100 / (1 + gain / loss))\n",
        "    return df\n",
        "\n",
        "def calculate_atr(df, period=14):\n",
        "    \"\"\"Calculate ATR and ATR%\"\"\"\n",
        "    df = df.copy()\n",
        "    df['atr'] = (df['high'] - df['low']).rolling(period).mean()\n",
        "    df['atr_pct'] = df['atr'] / df['close'] * 100\n",
        "    return df\n",
        "\n",
        "def calculate_moving_averages(df):\n",
        "    \"\"\"Calculate common moving averages\"\"\"\n",
        "    df = df.copy()\n",
        "    df['ma20'] = df['close'].rolling(20).mean()\n",
        "    df['ma50'] = df['close'].rolling(50).mean()\n",
        "    df['ma200'] = df['close'].rolling(200).mean()\n",
        "    df['price_vs_ma20'] = (df['close'] - df['ma20']) / df['ma20'] * 100\n",
        "    df['price_vs_ma50'] = (df['close'] - df['ma50']) / df['ma50'] * 100\n",
        "    df['price_vs_ma200'] = (df['close'] - df['ma200']) / df['ma200'] * 100\n",
        "    return df\n",
        "\n",
        "def calculate_returns(df):\n",
        "    \"\"\"Calculate various return periods\"\"\"\n",
        "    df = df.copy()\n",
        "    df['ret_1h'] = df['close'].pct_change() * 100\n",
        "    df['ret_4h'] = df['close'].pct_change(4) * 100\n",
        "    df['ret_24h'] = df['close'].pct_change(24) * 100\n",
        "    return df\n",
        "\n",
        "def calculate_bollinger_bands(df, period=20, std_dev=2):\n",
        "    \"\"\"Calculate Bollinger Bands\"\"\"\n",
        "    df = df.copy()\n",
        "    df['bb_mid'] = df['close'].rolling(period).mean()\n",
        "    df['bb_std'] = df['close'].rolling(period).std()\n",
        "    df['bb_upper'] = df['bb_mid'] + (df['bb_std'] * std_dev)\n",
        "    df['bb_lower'] = df['bb_mid'] - (df['bb_std'] * std_dev)\n",
        "    df['bb_pct'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])\n",
        "    df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_mid'] * 100\n",
        "    return df\n",
        "\n",
        "def calculate_momentum(df):\n",
        "    \"\"\"Calculate momentum indicators\"\"\"\n",
        "    df = df.copy()\n",
        "    df['roc_5'] = (df['close'] / df['close'].shift(5) - 1) * 100\n",
        "    df['roc_10'] = (df['close'] / df['close'].shift(10) - 1) * 100\n",
        "    \n",
        "    # MACD\n",
        "    ema12 = df['close'].ewm(span=12, adjust=False).mean()\n",
        "    ema26 = df['close'].ewm(span=26, adjust=False).mean()\n",
        "    df['macd'] = ema12 - ema26\n",
        "    df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()\n",
        "    df['macd_hist'] = df['macd'] - df['macd_signal']\n",
        "    \n",
        "    # Stochastic RSI\n",
        "    rsi = df['rsi'] if 'rsi' in df.columns else calculate_rsi(df)['rsi']\n",
        "    rsi_min = rsi.rolling(14).min()\n",
        "    rsi_max = rsi.rolling(14).max()\n",
        "    df['stoch_rsi'] = (rsi - rsi_min) / (rsi_max - rsi_min) * 100\n",
        "    return df\n",
        "\n",
        "def calculate_time_features(df):\n",
        "    \"\"\"Add time-based features\"\"\"\n",
        "    df = df.copy()\n",
        "    if isinstance(df.index, pd.DatetimeIndex):\n",
        "        df['hour'] = df.index.hour\n",
        "        df['day_of_week'] = df.index.dayofweek\n",
        "        df['is_london'] = ((df['hour'] >= 8) & (df['hour'] <= 16)).astype(int)\n",
        "        df['is_ny'] = ((df['hour'] >= 13) & (df['hour'] <= 21)).astype(int)\n",
        "        df['is_overlap'] = ((df['hour'] >= 13) & (df['hour'] <= 16)).astype(int)\n",
        "    return df\n",
        "\n",
        "def calculate_trend(df):\n",
        "    \"\"\"Calculate trend indicators\"\"\"\n",
        "    df = df.copy()\n",
        "    df['trend_20_50'] = np.where(df['ma20'] > df['ma50'], 1, -1)\n",
        "    df['trend_50_200'] = np.where(df['ma50'] > df['ma200'], 1, -1)\n",
        "    df['trend_score'] = df['trend_20_50'] + df['trend_50_200']\n",
        "    return df\n",
        "\n",
        "def calculate_volatility(df):\n",
        "    \"\"\"Calculate volatility features\"\"\"\n",
        "    df = df.copy()\n",
        "    df['volatility_24h'] = df['ret_1h'].rolling(24).std()\n",
        "    df['volatility_week'] = df['ret_1h'].rolling(168).std()\n",
        "    df['vol_ratio'] = df['volatility_24h'] / df['volatility_week']\n",
        "    return df\n",
        "\n",
        "def add_all_indicators(df):\n",
        "    \"\"\"Add all indicators\"\"\"\n",
        "    df = calculate_wavetrend(df)\n",
        "    df = calculate_wolfpack(df)\n",
        "    df = calculate_rsi(df)\n",
        "    df = calculate_atr(df)\n",
        "    df = calculate_moving_averages(df)\n",
        "    df = calculate_returns(df)\n",
        "    df = calculate_bollinger_bands(df)\n",
        "    df = calculate_momentum(df)\n",
        "    df = calculate_time_features(df)\n",
        "    df = calculate_trend(df)\n",
        "    df = calculate_volatility(df)\n",
        "    return df\n",
        "\n",
        "print(\"Indicator functions defined!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# LOAD DATA\n",
        "# ============================================================\n",
        "\n",
        "df = pd.read_csv('data/XAUUSD_KAGGLE_1h.csv', parse_dates=['datetime'], index_col='datetime')\n",
        "print(f\"Loaded {len(df):,} bars\")\n",
        "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
        "print(f\"\\nPrice range: ${df['close'].min():.2f} - ${df['close'].max():.2f}\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# CALCULATE ALL INDICATORS\n",
        "# ============================================================\n",
        "\n",
        "print(\"Calculating indicators...\")\n",
        "df = add_all_indicators(df)\n",
        "print(f\"Total columns: {len(df.columns)}\")\n",
        "print(f\"\\nIndicator columns:\")\n",
        "print([c for c in df.columns if c not in ['open', 'high', 'low', 'close', 'volume']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# CREATE TARGET VARIABLE\n",
        "# ============================================================\n",
        "\n",
        "LOOKAHEAD_HOURS = 24\n",
        "TARGET_PCT = 0.5  # 0.5% move = profitable trade\n",
        "\n",
        "# Future max price in next 24 hours\n",
        "df['future_max'] = df['high'].rolling(LOOKAHEAD_HOURS).max().shift(-LOOKAHEAD_HOURS)\n",
        "df['future_return'] = (df['future_max'] - df['close']) / df['close'] * 100\n",
        "\n",
        "# Target: Did price reach +0.5% in next 24 hours?\n",
        "df['target'] = (df['future_return'] >= TARGET_PCT).astype(int)\n",
        "\n",
        "print(f\"Target distribution:\")\n",
        "print(df['target'].value_counts(normalize=True))\n",
        "print(f\"\\nTarget 1 = price went up {TARGET_PCT}% within {LOOKAHEAD_HOURS} hours\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# DEFINE FEATURES\n",
        "# ============================================================\n",
        "\n",
        "# All available features for pure learning\n",
        "FEATURES = [\n",
        "    # Core momentum\n",
        "    'wt1', 'wt2', 'wolfpack', 'rsi', 'stoch_rsi',\n",
        "    \n",
        "    # Price position\n",
        "    'price_vs_ma20', 'price_vs_ma50', 'price_vs_ma200',\n",
        "    'bb_pct', 'bb_width',\n",
        "    \n",
        "    # Momentum\n",
        "    'roc_5', 'roc_10', 'macd_hist',\n",
        "    \n",
        "    # Volatility\n",
        "    'atr_pct', 'volatility_24h', 'vol_ratio',\n",
        "    \n",
        "    # Trend\n",
        "    'trend_score',\n",
        "    \n",
        "    # Returns\n",
        "    'ret_1h', 'ret_4h', 'ret_24h',\n",
        "    \n",
        "    # Time\n",
        "    'hour', 'day_of_week', 'is_overlap'\n",
        "]\n",
        "\n",
        "print(f\"Using {len(FEATURES)} features:\")\n",
        "print(FEATURES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# PREPARE DATA WITH TIME-BASED SPLIT\n",
        "# ============================================================\n",
        "\n",
        "# Drop rows with NaN\n",
        "df_clean = df.dropna(subset=FEATURES + ['target'])\n",
        "print(f\"Clean rows: {len(df_clean):,} (dropped {len(df) - len(df_clean):,} rows with NaN)\")\n",
        "\n",
        "# Time-based split: Train on older data, test on newer\n",
        "# Use 80% for training, 20% for testing (chronological)\n",
        "split_idx = int(len(df_clean) * 0.8)\n",
        "split_date = df_clean.index[split_idx]\n",
        "\n",
        "train_df = df_clean.iloc[:split_idx]\n",
        "test_df = df_clean.iloc[split_idx:]\n",
        "\n",
        "print(f\"\\nTrain period: {train_df.index.min()} to {train_df.index.max()} ({len(train_df):,} bars)\")\n",
        "print(f\"Test period:  {test_df.index.min()} to {test_df.index.max()} ({len(test_df):,} bars)\")\n",
        "\n",
        "X_train = train_df[FEATURES]\n",
        "y_train = train_df['target']\n",
        "X_test = test_df[FEATURES]\n",
        "y_test = test_df['target']\n",
        "\n",
        "print(f\"\\nTrain target distribution: {y_train.mean():.1%} positive\")\n",
        "print(f\"Test target distribution: {y_test.mean():.1%} positive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# SCALE FEATURES\n",
        "# ============================================================\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Features scaled with StandardScaler\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# TRAIN PURE MODEL\n",
        "# ============================================================\n",
        "\n",
        "print(\"Training XGBoost model on full dataset...\")\n",
        "print(\"This is a PURE learning model - no human bias, just learns from data.\")\n",
        "print()\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    min_child_weight=3,\n",
        "    gamma=0.1,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss',\n",
        "    early_stopping_rounds=20\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    eval_set=[(X_test_scaled, y_test)],\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "print(f\"Model trained! Best iteration: {model.best_iteration}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# EVALUATE MODEL\n",
        "# ============================================================\n",
        "\n",
        "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"MODEL EVALUATION ON TEST SET\")\n",
        "print(f\"Test period: {test_df.index.min().date()} to {test_df.index.max().date()}\")\n",
        "print(\"=\" * 50)\n",
        "print()\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# FEATURE IMPORTANCE\n",
        "# ============================================================\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': FEATURES,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(importance_df['feature'], importance_df['importance'])\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Feature Importance - Pure Learning Model')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTop 10 Features:\")\n",
        "print(importance_df.head(10).to_string(index=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# BACKTEST WITH THRESHOLD OPTIMIZATION\n",
        "# ============================================================\n",
        "\n",
        "def backtest_signals(df, predictions, threshold=0.5, tp_pct=0.5, sl_pct=0.3):\n",
        "    \"\"\"Backtest trading signals\"\"\"\n",
        "    trades = []\n",
        "    df = df.copy()\n",
        "    df['pred'] = predictions\n",
        "    \n",
        "    for i, (idx, row) in enumerate(df.iterrows()):\n",
        "        if row['pred'] < threshold:\n",
        "            continue\n",
        "            \n",
        "        entry_price = row['close']\n",
        "        tp_price = entry_price * (1 + tp_pct/100)\n",
        "        sl_price = entry_price * (1 - sl_pct/100)\n",
        "        \n",
        "        # Look ahead for exit\n",
        "        future = df.iloc[i+1:i+25]  # Next 24 bars\n",
        "        \n",
        "        hit_tp = False\n",
        "        hit_sl = False\n",
        "        exit_price = entry_price\n",
        "        \n",
        "        for _, future_row in future.iterrows():\n",
        "            if future_row['high'] >= tp_price:\n",
        "                hit_tp = True\n",
        "                exit_price = tp_price\n",
        "                break\n",
        "            if future_row['low'] <= sl_price:\n",
        "                hit_sl = True\n",
        "                exit_price = sl_price\n",
        "                break\n",
        "        \n",
        "        if not hit_tp and not hit_sl:\n",
        "            # Time exit at last bar\n",
        "            if len(future) > 0:\n",
        "                exit_price = future.iloc[-1]['close']\n",
        "        \n",
        "        pnl_pct = (exit_price - entry_price) / entry_price * 100\n",
        "        \n",
        "        trades.append({\n",
        "            'entry_time': idx,\n",
        "            'entry_price': entry_price,\n",
        "            'exit_price': exit_price,\n",
        "            'pnl_pct': pnl_pct,\n",
        "            'hit_tp': hit_tp,\n",
        "            'hit_sl': hit_sl,\n",
        "            'confidence': row['pred']\n",
        "        })\n",
        "    \n",
        "    return pd.DataFrame(trades)\n",
        "\n",
        "print(\"Testing different thresholds...\")\n",
        "print()\n",
        "\n",
        "test_df_bt = test_df.copy()\n",
        "test_df_bt['pred'] = y_pred_proba\n",
        "\n",
        "results = []\n",
        "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
        "    trades = backtest_signals(test_df_bt, y_pred_proba, threshold=threshold)\n",
        "    if len(trades) > 0:\n",
        "        win_rate = (trades['pnl_pct'] > 0).mean() * 100\n",
        "        total_return = trades['pnl_pct'].sum()\n",
        "        avg_return = trades['pnl_pct'].mean()\n",
        "        sharpe = trades['pnl_pct'].mean() / trades['pnl_pct'].std() * np.sqrt(252) if trades['pnl_pct'].std() > 0 else 0\n",
        "        \n",
        "        results.append({\n",
        "            'threshold': threshold,\n",
        "            'trades': len(trades),\n",
        "            'win_rate': win_rate,\n",
        "            'avg_return': avg_return,\n",
        "            'total_return': total_return,\n",
        "            'sharpe': sharpe\n",
        "        })\n",
        "        \n",
        "        print(f\"Threshold {threshold}: {len(trades):,} trades, {win_rate:.1f}% win, {total_return:.1f}% total, Sharpe {sharpe:.2f}\")\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print()\n",
        "print(results_df.to_string(index=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# DETAILED ANALYSIS BY YEAR\n",
        "# ============================================================\n",
        "\n",
        "test_df_bt['year'] = test_df_bt.index.year\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PERFORMANCE BY YEAR (threshold=0.5)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for year in sorted(test_df_bt['year'].unique()):\n",
        "    year_df = test_df_bt[test_df_bt['year'] == year]\n",
        "    year_preds = year_df['pred'].values\n",
        "    \n",
        "    trades = backtest_signals(year_df, year_preds, threshold=0.5)\n",
        "    if len(trades) > 0:\n",
        "        win_rate = (trades['pnl_pct'] > 0).mean() * 100\n",
        "        total_return = trades['pnl_pct'].sum()\n",
        "        sharpe = trades['pnl_pct'].mean() / trades['pnl_pct'].std() * np.sqrt(252) if trades['pnl_pct'].std() > 0 else 0\n",
        "        print(f\"{year}: {len(trades):4d} trades, {win_rate:5.1f}% win, {total_return:8.1f}% return, Sharpe {sharpe:5.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# SAVE MODELS\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "os.makedirs('models/v1.0', exist_ok=True)\n",
        "\n",
        "joblib.dump(model, 'models/v1.0/pure_model.pkl')\n",
        "joblib.dump(scaler, 'models/v1.0/scaler.pkl')\n",
        "\n",
        "# Save config\n",
        "import json\n",
        "\n",
        "best_result = results_df.loc[results_df['sharpe'].idxmax()]\n",
        "\n",
        "config = {\n",
        "    'version': '1.0',\n",
        "    'date': str(pd.Timestamp.now().date()),\n",
        "    'training_period': f\"{train_df.index.min().date()} to {train_df.index.max().date()}\",\n",
        "    'test_period': f\"{test_df.index.min().date()} to {test_df.index.max().date()}\",\n",
        "    'train_bars': len(train_df),\n",
        "    'test_bars': len(test_df),\n",
        "    'features': FEATURES,\n",
        "    'lookahead_hours': LOOKAHEAD_HOURS,\n",
        "    'target_pct': TARGET_PCT,\n",
        "    'model_params': {\n",
        "        'n_estimators': 200,\n",
        "        'max_depth': 6,\n",
        "        'learning_rate': 0.1,\n",
        "        'subsample': 0.8,\n",
        "        'colsample_bytree': 0.8\n",
        "    },\n",
        "    'best_threshold': float(best_result['threshold']),\n",
        "    'performance': {\n",
        "        'trades': int(best_result['trades']),\n",
        "        'win_rate': float(best_result['win_rate']),\n",
        "        'total_return': float(best_result['total_return']),\n",
        "        'sharpe': float(best_result['sharpe'])\n",
        "    },\n",
        "    'all_thresholds': results_df.to_dict('records')\n",
        "}\n",
        "\n",
        "with open('models/v1.0/config.json', 'w') as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "print(\"Models saved to models/v1.0/\")\n",
        "print(f\"\\nBest configuration:\")\n",
        "print(f\"  Threshold: {best_result['threshold']}\")\n",
        "print(f\"  Trades: {int(best_result['trades']):,}\")\n",
        "print(f\"  Win Rate: {best_result['win_rate']:.1f}%\")\n",
        "print(f\"  Total Return: {best_result['total_return']:.1f}%\")\n",
        "print(f\"  Sharpe: {best_result['sharpe']:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# SUMMARY\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PURE MODEL v1.0 - SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\"\"\\nThis model was trained on {len(train_df):,} hours of Gold data from {train_df.index.min().date()} to {train_df.index.max().date()}.\n",
        "\n",
        "It learns purely from the data without any human-imposed trading rules.\n",
        "The target is simple: predict if Gold will rise {TARGET_PCT}% within the next {LOOKAHEAD_HOURS} hours.\n",
        "\n",
        "Key findings:\n",
        "- Best Sharpe ratio achieved at threshold {best_result['threshold']}\n",
        "- Model uses {len(FEATURES)} features derived from price action\n",
        "\n",
        "Top predictive features:\"\"\")\n",
        "\n",
        "print(importance_df.head(5).to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
