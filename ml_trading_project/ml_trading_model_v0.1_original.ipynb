{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold Trading ML Model\n",
    "\n",
    "Two approaches:\n",
    "1. **Guided Model** - Trained on actual trades (mean-reversion style)\n",
    "2. **Pure Model** - Learns from scratch (price prediction)\n",
    "\n",
    "Run all cells to train and compare both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup - NO cloning needed, all functions are inlined\nimport os\n\nIN_COLAB = 'google.colab' in str(get_ipython()) if hasattr(__builtins__, '__IPYTHON__') else False\n\nif IN_COLAB:\n    # Download data files directly from GitHub\n    !wget -q https://raw.githubusercontent.com/altommo/gold-ml-trading/main/data/XAUUSD_1h.csv -O XAUUSD_1h.csv\n    !wget -q https://raw.githubusercontent.com/altommo/gold-ml-trading/main/data/trades_with_features.csv -O trades_with_features.csv\n    !pip install xgboost -q\n    print(\"Setup complete!\")\nelse:\n    print(\"Running locally\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Imports and Simple Indicator Functions (v0.1 - inlined to avoid loading new indicators.py)\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom xgboost import XGBClassifier\nimport joblib\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ===== SIMPLE INDICATOR FUNCTIONS (v0.1) =====\ndef calculate_wavetrend(df, n1=10, n2=21):\n    df = df.copy()\n    ap = (df['high'] + df['low'] + df['close']) / 3\n    esa = ap.ewm(span=n1, adjust=False).mean()\n    d = (ap - esa).abs().ewm(span=n1, adjust=False).mean()\n    ci = (ap - esa) / (0.015 * d)\n    df['wt1'] = ci.ewm(span=n2, adjust=False).mean()\n    df['wt2'] = df['wt1'].rolling(4).mean()\n    return df\n\ndef calculate_wolfpack(df):\n    df = df.copy()\n    df['wolfpack'] = df['close'].ewm(span=3, adjust=False).mean() - df['close'].ewm(span=8, adjust=False).mean()\n    return df\n\ndef calculate_rsi(df, period=14):\n    df = df.copy()\n    delta = df['close'].diff()\n    gain = delta.clip(lower=0).rolling(period).mean()\n    loss = (-delta.clip(upper=0)).rolling(period).mean()\n    df['rsi'] = 100 - (100 / (1 + gain / loss))\n    return df\n\ndef calculate_atr(df, period=14):\n    df = df.copy()\n    df['atr'] = (df['high'] - df['low']).rolling(period).mean()\n    df['atr_pct'] = df['atr'] / df['close'] * 100\n    return df\n\ndef calculate_moving_averages(df):\n    df = df.copy()\n    df['ma20'] = df['close'].rolling(20).mean()\n    df['ma50'] = df['close'].rolling(50).mean()\n    df['ma200'] = df['close'].rolling(200).mean()\n    df['price_vs_ma20'] = (df['close'] - df['ma20']) / df['ma20'] * 100\n    df['price_vs_ma50'] = (df['close'] - df['ma50']) / df['ma50'] * 100\n    return df\n\ndef calculate_returns(df):\n    df = df.copy()\n    df['ret_1h'] = df['close'].pct_change() * 100\n    df['ret_4h'] = df['close'].pct_change(4) * 100\n    df['ret_24h'] = df['close'].pct_change(24) * 100\n    return df\n\ndef add_all_indicators(df):\n    df = calculate_wavetrend(df)\n    df = calculate_wolfpack(df)\n    df = calculate_rsi(df)\n    df = calculate_atr(df)\n    df = calculate_moving_averages(df)\n    df = calculate_returns(df)\n    df['volatility'] = df['ret_1h'].rolling(24).std()\n    df['trend'] = np.where(df['ma20'] > df['ma50'], 1, -1)\n    return df\n\n# ===== BACKTEST FUNCTION =====\ndef backtest_model(df, model, scaler, features, threshold=0.5, hold_hours=24):\n    df = df.copy()\n    df = df.dropna(subset=features)\n    X = scaler.transform(df[features])\n    df['prob'] = model.predict_proba(X)[:, 1]\n    df['signal'] = (df['prob'] > threshold).astype(int)\n    df['future_ret'] = (df['close'].shift(-hold_hours) / df['close'] - 1) * 100\n    trades = df[df['signal'] == 1].copy()\n    if len(trades) == 0:\n        return {'total_trades': 0, 'avg_return': 0, 'total_return': 0, 'win_rate': 0, 'sharpe': 0}, pd.DataFrame()\n    results = {\n        'total_trades': len(trades),\n        'avg_return': trades['future_ret'].mean(),\n        'total_return': trades['future_ret'].sum(),\n        'win_rate': (trades['future_ret'] > 0).mean() * 100,\n        'sharpe': trades['future_ret'].mean() / trades['future_ret'].std() * np.sqrt(252) if trades['future_ret'].std() > 0 else 0\n    }\n    return results, trades\n\nprint(\"Libraries and functions loaded (v0.1 simple indicators)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load chart data\ndata_path = 'XAUUSD_1h.csv' if IN_COLAB else 'data/XAUUSD_1h.csv'\nchart_df = pd.read_csv(data_path, index_col=0, parse_dates=True)\nprint(f\"Chart data: {len(chart_df)} bars\")\nprint(f\"Date range: {chart_df.index.min()} to {chart_df.index.max()}\")\n\n# Add indicators\nchart_df = add_all_indicators(chart_df)\nprint(\"Indicators calculated\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load trades\ntrades_path = 'trades_with_features.csv' if IN_COLAB else 'data/trades_with_features.csv'\ntrades_df = pd.read_csv(trades_path, parse_dates=['entry_time', 'exit_time', 'chart_time'])\nprint(f\"Trades: {len(trades_df)}\")\nprint(f\"Winners: {len(trades_df[trades_df['won']])}, Losers: {len(trades_df[~trades_df['won']])}\")\nprint(f\"Win Rate: {trades_df['won'].mean()*100:.1f}%\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features\n",
    "FEATURES = ['wt1', 'wt2', 'wolfpack', 'rsi', 'atr_pct', \n",
    "            'price_vs_ma20', 'price_vs_ma50', 'ret_1h', 'ret_4h', 'ret_24h']\n",
    "\n",
    "# Separate buys and sells\n",
    "buys = trades_df[trades_df['direction'] == 'Buy']\n",
    "sells = trades_df[trades_df['direction'] == 'Sell']\n",
    "\n",
    "print(f\"Buys: {len(buys)}, Sells: {len(sells)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Your Trading Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your entry patterns\n",
    "print(\"=== YOUR BUY ENTRIES ===\")\n",
    "print(buys[FEATURES].mean())\n",
    "\n",
    "print(\"\\n=== YOUR SELL ENTRIES ===\")\n",
    "print(sells[FEATURES].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize your entry conditions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# WT distribution\n",
    "axes[0, 0].hist(buys['wt1'].dropna(), bins=30, alpha=0.7, label='Your Buys', color='green')\n",
    "axes[0, 0].hist(sells['wt1'].dropna(), bins=30, alpha=0.7, label='Your Sells', color='red')\n",
    "axes[0, 0].axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0, 0].set_title('WaveTrend at Entry')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# RSI\n",
    "axes[0, 1].hist(buys['rsi'].dropna(), bins=30, alpha=0.7, label='Your Buys', color='green')\n",
    "axes[0, 1].hist(sells['rsi'].dropna(), bins=30, alpha=0.7, label='Your Sells', color='red')\n",
    "axes[0, 1].axvline(x=50, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0, 1].set_title('RSI at Entry')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Wolfpack\n",
    "axes[1, 0].hist(buys['wolfpack'].dropna(), bins=30, alpha=0.7, label='Your Buys', color='green')\n",
    "axes[1, 0].hist(sells['wolfpack'].dropna(), bins=30, alpha=0.7, label='Your Sells', color='red')\n",
    "axes[1, 0].axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1, 0].set_title('Wolfpack at Entry')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Price vs MA20\n",
    "axes[1, 1].hist(buys['price_vs_ma20'].dropna(), bins=30, alpha=0.7, label='Your Buys', color='green')\n",
    "axes[1, 1].hist(sells['price_vs_ma20'].dropna(), bins=30, alpha=0.7, label='Your Sells', color='red')\n",
    "axes[1, 1].axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1, 1].set_title('Price vs MA20 % at Entry')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPattern: You BUY when indicators are LOW (dips), SELL when HIGH (rips)\")\n",
    "print(\"This is MEAN REVERSION trading.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Training Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label chart data based on your trades\n",
    "def create_guided_labels(df, buy_trades, sell_trades):\n",
    "    \"\"\"Mark bars where you traded\"\"\"\n",
    "    df = df.copy()\n",
    "    df['label_buy'] = 0\n",
    "    df['label_sell'] = 0\n",
    "    \n",
    "    for _, trade in buy_trades.iterrows():\n",
    "        if pd.isna(trade['chart_time']):\n",
    "            continue\n",
    "        mask = (df.index >= trade['chart_time'] - pd.Timedelta(hours=1)) & \\\n",
    "               (df.index <= trade['chart_time'] + pd.Timedelta(hours=1))\n",
    "        df.loc[mask, 'label_buy'] = 1\n",
    "    \n",
    "    for _, trade in sell_trades.iterrows():\n",
    "        if pd.isna(trade['chart_time']):\n",
    "            continue\n",
    "        mask = (df.index >= trade['chart_time'] - pd.Timedelta(hours=1)) & \\\n",
    "               (df.index <= trade['chart_time'] + pd.Timedelta(hours=1))\n",
    "        df.loc[mask, 'label_sell'] = 1\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Label for pure model (predict future price)\n",
    "LOOKAHEAD = 24  # hours\n",
    "TARGET_PCT = 0.5  # % gain\n",
    "\n",
    "chart_df['future_ret'] = (chart_df['close'].shift(-LOOKAHEAD) / chart_df['close'] - 1) * 100\n",
    "chart_df['label_pure_buy'] = (chart_df['future_ret'] > TARGET_PCT).astype(int)\n",
    "chart_df['label_pure_sell'] = (chart_df['future_ret'] < -TARGET_PCT).astype(int)\n",
    "\n",
    "# Add guided labels\n",
    "chart_df = create_guided_labels(chart_df, buys, sells)\n",
    "\n",
    "print(f\"Guided buy labels: {chart_df['label_buy'].sum()}\")\n",
    "print(f\"Guided sell labels: {chart_df['label_sell'].sum()}\")\n",
    "print(f\"Pure buy labels: {chart_df['label_pure_buy'].sum()} ({chart_df['label_pure_buy'].mean()*100:.1f}%)\")\n",
    "print(f\"Pure sell labels: {chart_df['label_pure_sell'].sum()} ({chart_df['label_pure_sell'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Guided Model (Your Style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "df_train = chart_df.dropna(subset=FEATURES + ['label_buy'])\n",
    "X = df_train[FEATURES]\n",
    "y = df_train['label_buy']\n",
    "\n",
    "print(f\"Training samples: {len(X)}\")\n",
    "print(f\"Positive samples: {y.sum()} ({y.mean()*100:.2f}%)\")\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale\n",
    "scaler_guided = StandardScaler()\n",
    "X_train_scaled = scaler_guided.fit_transform(X_train)\n",
    "X_test_scaled = scaler_guided.transform(X_test)\n",
    "\n",
    "# Class weights for imbalance\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "print(f\"Class weights: {weight_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Guided Buy Model\n",
    "guided_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=weight_dict[1]/weight_dict[0] if 0 in weight_dict and 1 in weight_dict else 1,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "guided_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = guided_model.predict(X_test_scaled)\n",
    "y_prob = guided_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"=== GUIDED MODEL RESULTS ===\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance - Guided\n",
    "importance_guided = pd.DataFrame({\n",
    "    'feature': FEATURES,\n",
    "    'importance': guided_model.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_guided['feature'], importance_guided['importance'])\n",
    "plt.title('Guided Model - What Features Matter for YOUR Entries')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Pure Model (From Scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure model training data\n",
    "df_pure = chart_df.dropna(subset=FEATURES + ['label_pure_buy'])\n",
    "X_pure = df_pure[FEATURES]\n",
    "y_pure = df_pure['label_pure_buy']\n",
    "\n",
    "print(f\"Training samples: {len(X_pure)}\")\n",
    "print(f\"Positive samples: {y_pure.sum()} ({y_pure.mean()*100:.1f}%)\")\n",
    "\n",
    "# Split\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_pure, y_pure, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale\n",
    "scaler_pure = StandardScaler()\n",
    "X_train_p_scaled = scaler_pure.fit_transform(X_train_p)\n",
    "X_test_p_scaled = scaler_pure.transform(X_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Pure Model\n",
    "pure_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "pure_model.fit(X_train_p_scaled, y_train_p)\n",
    "\n",
    "y_pred_p = pure_model.predict(X_test_p_scaled)\n",
    "\n",
    "print(\"=== PURE MODEL RESULTS ===\")\n",
    "print(classification_report(y_test_p, y_pred_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance - Pure\n",
    "importance_pure = pd.DataFrame({\n",
    "    'feature': FEATURES,\n",
    "    'importance': pure_model.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_pure['feature'], importance_pure['importance'])\n",
    "plt.title('Pure Model - What Features Predict Price Going Up')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side by side comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "axes[0].barh(importance_guided['feature'], importance_guided['importance'], color='blue')\n",
    "axes[0].set_title('GUIDED: Your Trading Style')\n",
    "axes[0].set_xlabel('Importance')\n",
    "\n",
    "axes[1].barh(importance_pure['feature'], importance_pure['importance'], color='orange')\n",
    "axes[1].set_title('PURE: Price Prediction')\n",
    "axes[1].set_xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDifference shows what YOU focus on vs what statistically predicts price movement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Backtest Both Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtest on last 500 bars (out of sample)\n",
    "test_data = chart_df.tail(500).copy()\n",
    "print(f\"Backtest period: {test_data.index.min()} to {test_data.index.max()}\")\n",
    "\n",
    "# Guided model backtest\n",
    "guided_results, guided_trades = backtest_model(\n",
    "    test_data, guided_model, scaler_guided, FEATURES, threshold=0.3, hold_hours=24\n",
    ")\n",
    "\n",
    "# Pure model backtest\n",
    "pure_results, pure_trades = backtest_model(\n",
    "    test_data, pure_model, scaler_pure, FEATURES, threshold=0.5, hold_hours=24\n",
    ")\n",
    "\n",
    "print(\"\\n=== BACKTEST COMPARISON ===\")\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': ['Trades', 'Win Rate %', 'Avg Return %', 'Total Return %', 'Sharpe'],\n",
    "    'Guided (Your Style)': [\n",
    "        guided_results['total_trades'],\n",
    "        f\"{guided_results['win_rate']:.1f}\",\n",
    "        f\"{guided_results['avg_return']:.2f}\",\n",
    "        f\"{guided_results['total_return']:.2f}\",\n",
    "        f\"{guided_results['sharpe']:.2f}\"\n",
    "    ],\n",
    "    'Pure (From Scratch)': [\n",
    "        pure_results['total_trades'],\n",
    "        f\"{pure_results['win_rate']:.1f}\",\n",
    "        f\"{pure_results['avg_return']:.2f}\",\n",
    "        f\"{pure_results['total_return']:.2f}\",\n",
    "        f\"{pure_results['sharpe']:.2f}\"\n",
    "    ]\n",
    "})\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Current Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current signal from latest bar\n",
    "latest = chart_df.dropna(subset=FEATURES).tail(1)\n",
    "\n",
    "if len(latest) > 0:\n",
    "    X_latest_g = scaler_guided.transform(latest[FEATURES])\n",
    "    X_latest_p = scaler_pure.transform(latest[FEATURES])\n",
    "    \n",
    "    guided_prob = guided_model.predict_proba(X_latest_g)[0, 1]\n",
    "    pure_prob = pure_model.predict_proba(X_latest_p)[0, 1]\n",
    "    \n",
    "    print(\"=== CURRENT SIGNAL ===\")\n",
    "    print(f\"Time: {latest.index[0]}\")\n",
    "    print(f\"Price: ${latest['close'].values[0]:.2f}\")\n",
    "    print(f\"\\nIndicators:\")\n",
    "    print(f\"  WaveTrend: {latest['wt1'].values[0]:.1f}\")\n",
    "    print(f\"  Wolfpack: {latest['wolfpack'].values[0]:.2f}\")\n",
    "    print(f\"  RSI: {latest['rsi'].values[0]:.1f}\")\n",
    "    print(f\"  Price vs MA20: {latest['price_vs_ma20'].values[0]:.2f}%\")\n",
    "    print(f\"\\nBUY Probability:\")\n",
    "    print(f\"  Guided (Your Style): {guided_prob*100:.1f}%\")\n",
    "    print(f\"  Pure (ML Optimal): {pure_prob*100:.1f}%\")\n",
    "    \n",
    "    # Signal interpretation\n",
    "    print(f\"\\nInterpretation:\")\n",
    "    if guided_prob > 0.3:\n",
    "        print(\"  Guided: This looks like YOUR kind of buy setup\")\n",
    "    else:\n",
    "        print(\"  Guided: Not matching your typical entry pattern\")\n",
    "    \n",
    "    if pure_prob > 0.5:\n",
    "        print(\"  Pure: ML predicts price likely to go up\")\n",
    "    else:\n",
    "        print(\"  Pure: ML doesn't see strong upside\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save models\nimport os\nos.makedirs('models', exist_ok=True)\n\njoblib.dump(guided_model, 'models/guided_model.pkl')\njoblib.dump(pure_model, 'models/pure_model.pkl')\njoblib.dump(scaler_guided, 'models/scaler_guided.pkl')\njoblib.dump(scaler_pure, 'models/scaler_pure.pkl')\n\nprint(\"Models saved to models/ folder\")\n\n# Download as zip if on Colab\nif IN_COLAB:\n    import shutil\n    shutil.make_archive('models_v0.1', 'zip', 'models')\n    from google.colab import files\n    files.download('models_v0.1.zip')\n    print(\"Downloaded models_v0.1.zip\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}