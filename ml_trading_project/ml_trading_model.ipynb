{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold Trading ML Model\n",
    "\n",
    "Two approaches:\n",
    "1. **Guided Model** - Trained on actual trades (mean-reversion style)\n",
    "2. **Pure Model** - Learns from scratch (price prediction)\n",
    "\n",
    "Run all cells to train and compare both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup - Clone repo if on Colab\nimport os\n\n# Check if running on Colab\nIN_COLAB = 'google.colab' in str(get_ipython()) if hasattr(__builtins__, '__IPYTHON__') else False\n\nif IN_COLAB:\n    # Clone or update the repo\n    if os.path.exists('gold-ml-trading'):\n        # Pull latest changes\n        os.chdir('gold-ml-trading')\n        !git pull\n    else:\n        !git clone https://github.com/altommo/gold-ml-trading.git\n        os.chdir('gold-ml-trading')\n    !pip install -r requirements.txt -q\n    print(\"Setup complete!\")\nelse:\n    print(\"Running locally\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Imports and Indicator Functions (all inline to avoid caching issues)\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom xgboost import XGBClassifier\nimport joblib\nimport json\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ===== INDICATOR FUNCTIONS =====\ndef calculate_wavetrend(df, n1=10, n2=21):\n    df = df.copy()\n    ap = (df['high'] + df['low'] + df['close']) / 3\n    esa = ap.ewm(span=n1, adjust=False).mean()\n    d = (ap - esa).abs().ewm(span=n1, adjust=False).mean()\n    ci = (ap - esa) / (0.015 * d)\n    df['wt1'] = ci.ewm(span=n2, adjust=False).mean()\n    df['wt2'] = df['wt1'].rolling(4).mean()\n    return df\n\ndef calculate_wolfpack(df):\n    df = df.copy()\n    df['wolfpack'] = df['close'].ewm(span=3, adjust=False).mean() - df['close'].ewm(span=8, adjust=False).mean()\n    return df\n\ndef calculate_rsi(df, period=14):\n    df = df.copy()\n    delta = df['close'].diff()\n    gain = delta.clip(lower=0).rolling(period).mean()\n    loss = (-delta.clip(upper=0)).rolling(period).mean()\n    df['rsi'] = 100 - (100 / (1 + gain / loss))\n    return df\n\ndef calculate_atr(df, period=14):\n    df = df.copy()\n    df['atr'] = (df['high'] - df['low']).rolling(period).mean()\n    df['atr_pct'] = df['atr'] / df['close'] * 100\n    return df\n\ndef calculate_moving_averages(df):\n    df = df.copy()\n    df['ma20'] = df['close'].rolling(20).mean()\n    df['ma50'] = df['close'].rolling(50).mean()\n    df['ma200'] = df['close'].rolling(200).mean()\n    df['price_vs_ma20'] = (df['close'] - df['ma20']) / df['ma20'] * 100\n    df['price_vs_ma50'] = (df['close'] - df['ma50']) / df['ma50'] * 100\n    return df\n\ndef calculate_returns(df):\n    df = df.copy()\n    df['ret_1h'] = df['close'].pct_change() * 100\n    df['ret_4h'] = df['close'].pct_change(4) * 100\n    df['ret_24h'] = df['close'].pct_change(24) * 100\n    return df\n\ndef calculate_bollinger_bands(df, period=20, std_dev=2):\n    df = df.copy()\n    df['bb_mid'] = df['close'].rolling(period).mean()\n    df['bb_std'] = df['close'].rolling(period).std()\n    df['bb_upper'] = df['bb_mid'] + (df['bb_std'] * std_dev)\n    df['bb_lower'] = df['bb_mid'] - (df['bb_std'] * std_dev)\n    df['bb_pct'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])\n    df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_mid'] * 100\n    return df\n\ndef calculate_momentum(df):\n    df = df.copy()\n    df['roc_5'] = (df['close'] / df['close'].shift(5) - 1) * 100\n    df['roc_10'] = (df['close'] / df['close'].shift(10) - 1) * 100\n    ema12 = df['close'].ewm(span=12, adjust=False).mean()\n    ema26 = df['close'].ewm(span=26, adjust=False).mean()\n    df['macd'] = ema12 - ema26\n    df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()\n    df['macd_hist'] = df['macd'] - df['macd_signal']\n    rsi = df['rsi'] if 'rsi' in df.columns else calculate_rsi(df)['rsi']\n    rsi_min = rsi.rolling(14).min()\n    rsi_max = rsi.rolling(14).max()\n    df['stoch_rsi'] = (rsi - rsi_min) / (rsi_max - rsi_min) * 100\n    return df\n\ndef calculate_time_features(df):\n    df = df.copy()\n    if isinstance(df.index, pd.DatetimeIndex):\n        df['hour'] = df.index.hour\n        df['day_of_week'] = df.index.dayofweek\n        df['is_overlap'] = ((df['hour'] >= 13) & (df['hour'] <= 17)).astype(int)\n    return df\n\ndef calculate_higher_tf_trend(df, periods=[24, 48, 96]):\n    df = df.copy()\n    for p in periods:\n        df[f'ma_{p}h'] = df['close'].rolling(p).mean()\n        df[f'trend_{p}h'] = np.where(df['close'] > df[f'ma_{p}h'], 1, -1)\n    df['trend_score'] = df['trend_24h'] + df['trend_48h'] + df['trend_96h']\n    return df\n\ndef calculate_wt_signals(df):\n    df = df.copy()\n    df['wt_distance'] = abs(df['wt1'])\n    return df\n\ndef add_all_indicators(df):\n    df = calculate_wavetrend(df)\n    df = calculate_wolfpack(df)\n    df = calculate_rsi(df)\n    df = calculate_atr(df)\n    df = calculate_moving_averages(df)\n    df = calculate_returns(df)\n    df = calculate_bollinger_bands(df)\n    df = calculate_momentum(df)\n    df = calculate_time_features(df)\n    df = calculate_higher_tf_trend(df)\n    df = calculate_wt_signals(df)\n    df['volatility'] = df['ret_1h'].rolling(24).std()\n    df['trend'] = np.where(df['ma20'] > df['ma50'], 1, -1)\n    return df\n\n# ===== BACKTEST FUNCTION =====\ndef backtest_model(df, model, scaler, features, threshold=0.5, hold_hours=24):\n    df = df.copy()\n    df = df.dropna(subset=features)\n    X = scaler.transform(df[features])\n    df['prob'] = model.predict_proba(X)[:, 1]\n    df['signal'] = (df['prob'] > threshold).astype(int)\n    df['future_ret'] = (df['close'].shift(-hold_hours) / df['close'] - 1) * 100\n    trades = df[df['signal'] == 1].copy()\n    if len(trades) == 0:\n        return {'total_trades': 0, 'avg_return': 0, 'total_return': 0, 'win_rate': 0, 'sharpe': 0}, pd.DataFrame()\n    results = {\n        'total_trades': len(trades),\n        'avg_return': trades['future_ret'].mean(),\n        'total_return': trades['future_ret'].sum(),\n        'win_rate': (trades['future_ret'] > 0).mean() * 100,\n        'sharpe': trades['future_ret'].mean() / trades['future_ret'].std() * np.sqrt(252) if trades['future_ret'].std() > 0 else 0\n    }\n    return results, trades\n\nprint(\"All functions loaded!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load chart data\n",
    "chart_df = pd.read_csv('data/XAUUSD_1h.csv', index_col=0, parse_dates=True)\n",
    "print(f\"Chart data: {len(chart_df)} bars\")\n",
    "print(f\"Date range: {chart_df.index.min()} to {chart_df.index.max()}\")\n",
    "\n",
    "# Add indicators\n",
    "chart_df = add_all_indicators(chart_df)\n",
    "print(\"Indicators calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trades\n",
    "trades_df = pd.read_csv('data/trades_with_features.csv', parse_dates=['entry_time', 'exit_time', 'chart_time'])\n",
    "print(f\"Trades: {len(trades_df)}\")\n",
    "print(f\"Winners: {len(trades_df[trades_df['won']])}, Losers: {len(trades_df[~trades_df['won']])}\")\n",
    "print(f\"Win Rate: {trades_df['won'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# EXPANDED feature list with new indicators\nFEATURES_BASIC = ['wt1', 'wt2', 'wolfpack', 'rsi', 'atr_pct', \n                  'price_vs_ma20', 'price_vs_ma50', 'ret_1h', 'ret_4h', 'ret_24h']\n\nFEATURES_EXTENDED = FEATURES_BASIC + [\n    'bb_pct', 'bb_width',           # Bollinger Bands\n    'roc_5', 'roc_10',              # Rate of change\n    'macd_hist', 'stoch_rsi',       # Momentum\n    'hour', 'is_overlap',           # Time features\n    'trend_score',                  # Higher TF trend\n    'wt_distance',                  # WT distance from zero\n    'volatility'                    # Volatility\n]\n\n# Use extended features\nFEATURES = FEATURES_EXTENDED\n\n# Separate buys and sells\nbuys = trades_df[trades_df['direction'] == 'Buy']\nsells = trades_df[trades_df['direction'] == 'Sell']\n\nprint(f\"Total features: {len(FEATURES)}\")\nprint(f\"Buys: {len(buys)}, Sells: {len(sells)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Your Trading Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Your entry patterns (using basic features that exist in trades file)\nprint(\"=== YOUR BUY ENTRIES ===\")\nprint(buys[FEATURES_BASIC].mean())\n\nprint(\"\\n=== YOUR SELL ENTRIES ===\")\nprint(sells[FEATURES_BASIC].mean())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize your entry conditions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# WT distribution\n",
    "axes[0, 0].hist(buys['wt1'].dropna(), bins=30, alpha=0.7, label='Your Buys', color='green')\n",
    "axes[0, 0].hist(sells['wt1'].dropna(), bins=30, alpha=0.7, label='Your Sells', color='red')\n",
    "axes[0, 0].axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0, 0].set_title('WaveTrend at Entry')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# RSI\n",
    "axes[0, 1].hist(buys['rsi'].dropna(), bins=30, alpha=0.7, label='Your Buys', color='green')\n",
    "axes[0, 1].hist(sells['rsi'].dropna(), bins=30, alpha=0.7, label='Your Sells', color='red')\n",
    "axes[0, 1].axvline(x=50, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0, 1].set_title('RSI at Entry')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Wolfpack\n",
    "axes[1, 0].hist(buys['wolfpack'].dropna(), bins=30, alpha=0.7, label='Your Buys', color='green')\n",
    "axes[1, 0].hist(sells['wolfpack'].dropna(), bins=30, alpha=0.7, label='Your Sells', color='red')\n",
    "axes[1, 0].axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1, 0].set_title('Wolfpack at Entry')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Price vs MA20\n",
    "axes[1, 1].hist(buys['price_vs_ma20'].dropna(), bins=30, alpha=0.7, label='Your Buys', color='green')\n",
    "axes[1, 1].hist(sells['price_vs_ma20'].dropna(), bins=30, alpha=0.7, label='Your Sells', color='red')\n",
    "axes[1, 1].axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1, 1].set_title('Price vs MA20 % at Entry')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPattern: You BUY when indicators are LOW (dips), SELL when HIGH (rips)\")\n",
    "print(\"This is MEAN REVERSION trading.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Training Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# IMPROVED: Create labels based on YOUR mean-reversion conditions + outcome\n# Instead of just marking where you traded, we label bars that:\n# 1. Match your entry conditions (mean-reversion)\n# 2. AND resulted in profitable moves\n\ndef create_mean_reversion_labels(df, lookahead=24, target_pct=0.5):\n    \"\"\"\n    Label bars that match mean-reversion buy conditions and led to profit.\n    Your style: Buy dips (WT negative, RSI low, price below MA)\n    \"\"\"\n    df = df.copy()\n    \n    # Future return for outcome\n    df['future_ret'] = (df['close'].shift(-lookahead) / df['close'] - 1) * 100\n    \n    # Mean-reversion BUY conditions (based on your actual trades)\n    buy_conditions = (\n        (df['wt1'] < 20) &          # WT not overbought\n        (df['rsi'] < 60) &           # RSI not high\n        (df['price_vs_ma20'] < 1.0)  # Not too far above MA20\n    )\n    \n    # Label = conditions met AND price went up\n    df['label_guided_buy'] = (buy_conditions & (df['future_ret'] > target_pct)).astype(int)\n    \n    # Mean-reversion SELL conditions\n    sell_conditions = (\n        (df['wt1'] > -20) &           # WT not oversold\n        (df['rsi'] > 40) &            # RSI not low\n        (df['price_vs_ma20'] > -1.0)  # Not too far below MA20\n    )\n    \n    df['label_guided_sell'] = (sell_conditions & (df['future_ret'] < -target_pct)).astype(int)\n    \n    return df\n\n# Pure model labels (simple price prediction)\nLOOKAHEAD = 24\nTARGET_PCT = 0.5\n\nchart_df['future_ret'] = (chart_df['close'].shift(-LOOKAHEAD) / chart_df['close'] - 1) * 100\nchart_df['label_pure_buy'] = (chart_df['future_ret'] > TARGET_PCT).astype(int)\nchart_df['label_pure_sell'] = (chart_df['future_ret'] < -TARGET_PCT).astype(int)\n\n# Guided labels with mean-reversion conditions\nchart_df = create_mean_reversion_labels(chart_df, lookahead=LOOKAHEAD, target_pct=TARGET_PCT)\n\nprint(f\"Guided buy labels: {chart_df['label_guided_buy'].sum()} ({chart_df['label_guided_buy'].mean()*100:.1f}%)\")\nprint(f\"Pure buy labels: {chart_df['label_pure_buy'].sum()} ({chart_df['label_pure_buy'].mean()*100:.1f}%)\")\nprint(f\"\\nGuided model now learns: 'When conditions match your style, did price go up?'\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Guided Model (Your Style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Prepare training data with EXTENDED features\ndf_train = chart_df.dropna(subset=FEATURES + ['label_guided_buy'])\nX = df_train[FEATURES]\ny = df_train['label_guided_buy']\n\nprint(f\"Training samples: {len(X)}\")\nprint(f\"Positive samples: {y.sum()} ({y.mean()*100:.2f}%)\")\n\n# Split - use time-based split for financial data\nsplit_idx = int(len(X) * 0.8)\nX_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\ny_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n\nprint(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n\n# Scale\nscaler_guided = StandardScaler()\nX_train_scaled = scaler_guided.fit_transform(X_train)\nX_test_scaled = scaler_guided.transform(X_test)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train Guided Model with FIXED PARAMS or HYPERPARAMETER TUNING\n# Set USE_FIXED_PARAMS = True to reproduce v0.1, False for hyperparameter search\nUSE_FIXED_PARAMS = True\n\n# Parameter grid for search (if USE_FIXED_PARAMS = False)\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [3, 5, 7, 10],\n    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n    'min_child_weight': [1, 3, 5],\n    'subsample': [0.7, 0.8, 0.9],\n    'colsample_bytree': [0.7, 0.8, 0.9],\n    'gamma': [0, 0.1, 0.2]\n}\n\nif USE_FIXED_PARAMS:\n    print(\"Using FIXED params (v0.1 config)...\")\n    guided_model = XGBClassifier(\n        n_estimators=200,\n        max_depth=3,\n        learning_rate=0.2,\n        min_child_weight=3,\n        subsample=0.8,\n        colsample_bytree=0.7,\n        gamma=0.1,\n        random_state=42,\n        eval_metric='logloss',\n        use_label_encoder=False\n    )\n    guided_model.fit(X_train_scaled, y_train)\n    search = type('obj', (object,), {'best_params_': guided_model.get_params()})()\nelse:\n    print(\"Tuning Guided Model hyperparameters...\")\n    search = RandomizedSearchCV(\n        XGBClassifier(random_state=42, eval_metric='logloss', use_label_encoder=False),\n        param_grid, \n        n_iter=30,\n        cv=3,\n        scoring='f1',\n        random_state=42,\n        n_jobs=-1\n    )\n    search.fit(X_train_scaled, y_train)\n    guided_model = search.best_estimator_\n    print(f\"Best params: {search.best_params_}\")\n\n# Evaluate on test set\ny_pred = guided_model.predict(X_test_scaled)\ny_prob = guided_model.predict_proba(X_test_scaled)[:, 1]\n\nprint(\"\\n=== GUIDED MODEL RESULTS ===\")\nprint(classification_report(y_test, y_pred))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Feature importance - Guided (top 15)\nimportance_guided = pd.DataFrame({\n    'feature': FEATURES,\n    'importance': guided_model.feature_importances_\n}).sort_values('importance', ascending=True).tail(15)\n\nplt.figure(figsize=(10, 8))\nplt.barh(importance_guided['feature'], importance_guided['importance'], color='steelblue')\nplt.title('Guided Model - Top 15 Features for YOUR Entry Style')\nplt.xlabel('Importance')\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nTop 5 features for Guided model:\")\nfor _, row in importance_guided.tail(5).iloc[::-1].iterrows():\n    print(f\"  {row['feature']}: {row['importance']:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Pure Model (From Scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Pure model training data with EXTENDED features\ndf_pure = chart_df.dropna(subset=FEATURES + ['label_pure_buy'])\nX_pure = df_pure[FEATURES]\ny_pure = df_pure['label_pure_buy']\n\nprint(f\"Training samples: {len(X_pure)}\")\nprint(f\"Positive samples: {y_pure.sum()} ({y_pure.mean()*100:.1f}%)\")\n\n# Time-based split\nsplit_idx = int(len(X_pure) * 0.8)\nX_train_p, X_test_p = X_pure.iloc[:split_idx], X_pure.iloc[split_idx:]\ny_train_p, y_test_p = y_pure.iloc[:split_idx], y_pure.iloc[split_idx:]\n\nprint(f\"Train: {len(X_train_p)}, Test: {len(X_test_p)}\")\n\n# Scale\nscaler_pure = StandardScaler()\nX_train_p_scaled = scaler_pure.fit_transform(X_train_p)\nX_test_p_scaled = scaler_pure.transform(X_test_p)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train Pure Model with FIXED PARAMS (v0.1 - 125% return config)\n# Set USE_FIXED_PARAMS = True to reproduce v0.1, False for hyperparameter search\nUSE_FIXED_PARAMS = True\n\nif USE_FIXED_PARAMS:\n    print(\"Using FIXED params (v0.1 config)...\")\n    pure_model = XGBClassifier(\n        n_estimators=300,\n        max_depth=10,\n        learning_rate=0.2,\n        min_child_weight=3,\n        subsample=0.7,\n        colsample_bytree=0.9,\n        gamma=0.1,\n        random_state=42,\n        eval_metric='logloss',\n        use_label_encoder=False\n    )\n    pure_model.fit(X_train_p_scaled, y_train_p)\n    search_pure = type('obj', (object,), {'best_params_': pure_model.get_params()})()\nelse:\n    print(\"Tuning Pure Model hyperparameters...\")\n    search_pure = RandomizedSearchCV(\n        XGBClassifier(random_state=42, eval_metric='logloss', use_label_encoder=False),\n        param_grid, \n        n_iter=30,\n        cv=3,\n        scoring='f1',\n        random_state=42,\n        n_jobs=-1\n    )\n    search_pure.fit(X_train_p_scaled, y_train_p)\n    pure_model = search_pure.best_estimator_\n    print(f\"Best params: {search_pure.best_params_}\")\n\ny_pred_p = pure_model.predict(X_test_p_scaled)\ny_prob_p = pure_model.predict_proba(X_test_p_scaled)[:, 1]\n\nprint(\"\\n=== PURE MODEL RESULTS ===\")\nprint(classification_report(y_test_p, y_pred_p))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Feature importance - Pure (top 15)\nimportance_pure = pd.DataFrame({\n    'feature': FEATURES,\n    'importance': pure_model.feature_importances_\n}).sort_values('importance', ascending=True).tail(15)\n\nplt.figure(figsize=(10, 8))\nplt.barh(importance_pure['feature'], importance_pure['importance'], color='darkorange')\nplt.title('Pure Model - Top 15 Features for Price Prediction')\nplt.xlabel('Importance')\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nTop 5 features for Pure model:\")\nfor _, row in importance_pure.tail(5).iloc[::-1].iterrows():\n    print(f\"  {row['feature']}: {row['importance']:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side by side comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "axes[0].barh(importance_guided['feature'], importance_guided['importance'], color='blue')\n",
    "axes[0].set_title('GUIDED: Your Trading Style')\n",
    "axes[0].set_xlabel('Importance')\n",
    "\n",
    "axes[1].barh(importance_pure['feature'], importance_pure['importance'], color='orange')\n",
    "axes[1].set_title('PURE: Price Prediction')\n",
    "axes[1].set_xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDifference shows what YOU focus on vs what statistically predicts price movement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Backtest Both Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Backtest on last 500 bars (out of sample)\ntest_data = chart_df.tail(500).copy()\nprint(f\"Backtest period: {test_data.index.min()} to {test_data.index.max()}\")\n\n# ===== THRESHOLD SETTINGS =====\n# Set to None for auto-optimization, or set fixed value (e.g. 0.5)\nFORCE_GUIDED_THRESHOLD = None  # e.g. 0.3\nFORCE_PURE_THRESHOLD = 0.5     # v0.1 used 0.5 for 125% return\n# ==============================\n\n# Find optimal thresholds\ndef optimize_threshold(df, model, scaler, features, thresholds=[0.3, 0.4, 0.5, 0.6, 0.7]):\n    \"\"\"Test different thresholds and find best one\"\"\"\n    results = []\n    for thresh in thresholds:\n        res, _ = backtest_model(df, model, scaler, features, threshold=thresh, hold_hours=24)\n        res['threshold'] = thresh\n        results.append(res)\n    return pd.DataFrame(results)\n\nprint(\"\\n=== THRESHOLD OPTIMIZATION ===\")\nthresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n\nguided_thresh_results = optimize_threshold(test_data, guided_model, scaler_guided, FEATURES, thresholds)\npure_thresh_results = optimize_threshold(test_data, pure_model, scaler_pure, FEATURES, thresholds)\n\n# Show all threshold results\nprint(\"\\nGuided threshold sweep:\")\nprint(guided_thresh_results[['threshold', 'total_trades', 'win_rate', 'total_return', 'sharpe']].to_string(index=False))\n\nprint(\"\\nPure threshold sweep:\")\nprint(pure_thresh_results[['threshold', 'total_trades', 'win_rate', 'total_return', 'sharpe']].to_string(index=False))\n\n# Use forced or optimized threshold\nif FORCE_GUIDED_THRESHOLD is not None:\n    best_guided_thresh = FORCE_GUIDED_THRESHOLD\n    print(f\"\\nUsing FORCED Guided threshold: {best_guided_thresh}\")\nelse:\n    best_guided_thresh = guided_thresh_results.loc[guided_thresh_results['sharpe'].idxmax(), 'threshold']\n    print(f\"\\nAuto-selected Guided threshold: {best_guided_thresh}\")\n\nif FORCE_PURE_THRESHOLD is not None:\n    best_pure_thresh = FORCE_PURE_THRESHOLD\n    print(f\"Using FORCED Pure threshold: {best_pure_thresh}\")\nelse:\n    best_pure_thresh = pure_thresh_results.loc[pure_thresh_results['sharpe'].idxmax(), 'threshold']\n    print(f\"Auto-selected Pure threshold: {best_pure_thresh}\")\n\n# Run with selected thresholds\nguided_results, guided_trades = backtest_model(\n    test_data, guided_model, scaler_guided, FEATURES, threshold=best_guided_thresh, hold_hours=24\n)\npure_results, pure_trades = backtest_model(\n    test_data, pure_model, scaler_pure, FEATURES, threshold=best_pure_thresh, hold_hours=24\n)\n\nprint(\"\\n=== BACKTEST COMPARISON ===\")\ncomparison = pd.DataFrame({\n    'Metric': ['Threshold', 'Trades', 'Win Rate %', 'Avg Return %', 'Total Return %', 'Sharpe'],\n    'Guided (Your Style)': [\n        f\"{best_guided_thresh}\",\n        guided_results['total_trades'],\n        f\"{guided_results['win_rate']:.1f}\",\n        f\"{guided_results['avg_return']:.2f}\",\n        f\"{guided_results['total_return']:.2f}\",\n        f\"{guided_results['sharpe']:.2f}\"\n    ],\n    'Pure (From Scratch)': [\n        f\"{best_pure_thresh}\",\n        pure_results['total_trades'],\n        f\"{pure_results['win_rate']:.1f}\",\n        f\"{pure_results['avg_return']:.2f}\",\n        f\"{pure_results['total_return']:.2f}\",\n        f\"{pure_results['sharpe']:.2f}\"\n    ]\n})\nprint(comparison.to_string(index=False))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Ensemble Model (Best of Both)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ENSEMBLE: Combine both models\n# Only take trades when BOTH models agree\n\ndef backtest_ensemble(df, guided_model, pure_model, scaler_g, scaler_p, features, \n                      g_thresh=0.5, p_thresh=0.5, hold_hours=24):\n    \"\"\"Backtest ensemble - only trade when both models agree\"\"\"\n    df = df.copy()\n    df = df.dropna(subset=features)\n    \n    X_g = scaler_g.transform(df[features])\n    X_p = scaler_p.transform(df[features])\n    \n    df['prob_guided'] = guided_model.predict_proba(X_g)[:, 1]\n    df['prob_pure'] = pure_model.predict_proba(X_p)[:, 1]\n    \n    # Ensemble: both must agree\n    df['signal'] = ((df['prob_guided'] > g_thresh) & (df['prob_pure'] > p_thresh)).astype(int)\n    \n    # Calculate future returns\n    df['future_ret'] = (df['close'].shift(-hold_hours) / df['close'] - 1) * 100\n    \n    trades = df[df['signal'] == 1].copy()\n    \n    if len(trades) == 0:\n        return {'total_trades': 0, 'avg_return': 0, 'total_return': 0, \n                'win_rate': 0, 'sharpe': 0, 'max_drawdown': 0}, pd.DataFrame()\n    \n    results = {\n        'total_trades': len(trades),\n        'avg_return': trades['future_ret'].mean(),\n        'total_return': trades['future_ret'].sum(),\n        'win_rate': (trades['future_ret'] > 0).mean() * 100,\n        'sharpe': trades['future_ret'].mean() / trades['future_ret'].std() * np.sqrt(252) if trades['future_ret'].std() > 0 else 0,\n        'max_drawdown': 0  # simplified\n    }\n    \n    return results, trades\n\n# Test ensemble with various threshold combinations\nprint(\"=== ENSEMBLE MODEL (Both Must Agree) ===\\n\")\n\nensemble_results = []\nfor g_t in [0.3, 0.4, 0.5]:\n    for p_t in [0.4, 0.5, 0.6]:\n        res, _ = backtest_ensemble(test_data, guided_model, pure_model, \n                                   scaler_guided, scaler_pure, FEATURES,\n                                   g_thresh=g_t, p_thresh=p_t)\n        res['g_thresh'] = g_t\n        res['p_thresh'] = p_t\n        ensemble_results.append(res)\n\nensemble_df = pd.DataFrame(ensemble_results)\nensemble_df = ensemble_df.sort_values('sharpe', ascending=False)\n\nprint(\"Top 5 Ensemble Configurations:\")\nprint(ensemble_df.head().to_string(index=False))\n\n# Best ensemble\nbest_g = ensemble_df.iloc[0]['g_thresh']\nbest_p = ensemble_df.iloc[0]['p_thresh']\nensemble_final, ensemble_trades = backtest_ensemble(\n    test_data, guided_model, pure_model, scaler_guided, scaler_pure, FEATURES,\n    g_thresh=best_g, p_thresh=best_p\n)\n\nprint(f\"\\n=== BEST ENSEMBLE (G={best_g}, P={best_p}) ===\")\nprint(f\"Trades: {ensemble_final['total_trades']}\")\nprint(f\"Win Rate: {ensemble_final['win_rate']:.1f}%\")\nprint(f\"Avg Return: {ensemble_final['avg_return']:.2f}%\")\nprint(f\"Total Return: {ensemble_final['total_return']:.2f}%\")\nprint(f\"Sharpe: {ensemble_final['sharpe']:.2f}\")"
  },
  {
   "cell_type": "code",
   "source": "# Get current signal from latest bar\nlatest = chart_df.dropna(subset=FEATURES).tail(1)\n\nif len(latest) > 0:\n    X_latest_g = scaler_guided.transform(latest[FEATURES])\n    X_latest_p = scaler_pure.transform(latest[FEATURES])\n    \n    guided_prob = guided_model.predict_proba(X_latest_g)[0, 1]\n    pure_prob = pure_model.predict_proba(X_latest_p)[0, 1]\n    \n    print(\"=\" * 50)\n    print(\"CURRENT SIGNAL\")\n    print(\"=\" * 50)\n    print(f\"Time: {latest.index[0]}\")\n    print(f\"Price: ${latest['close'].values[0]:.2f}\")\n    print(f\"\\nIndicators:\")\n    print(f\"  WaveTrend: {latest['wt1'].values[0]:.1f}\")\n    print(f\"  Wolfpack: {latest['wolfpack'].values[0]:.2f}\")\n    print(f\"  RSI: {latest['rsi'].values[0]:.1f}\")\n    print(f\"  Price vs MA20: {latest['price_vs_ma20'].values[0]:.2f}%\")\n    print(f\"  Trend Score: {latest['trend_score'].values[0]:.0f}\")\n    print(f\"\\nBUY Probability:\")\n    print(f\"  Guided (Your Style): {guided_prob*100:.1f}%\")\n    print(f\"  Pure (ML Optimal): {pure_prob*100:.1f}%\")\n    \n    # Ensemble signal\n    ensemble_signal = (guided_prob > best_g) and (pure_prob > best_p)\n    print(f\"\\n  ENSEMBLE SIGNAL: {'BUY' if ensemble_signal else 'NO TRADE'}\")\n    \n    print(f\"\\nInterpretation:\")\n    if guided_prob > best_g:\n        print(f\"  Guided: BULLISH - This matches your entry style\")\n    else:\n        print(f\"  Guided: NEUTRAL - Not your typical setup\")\n    \n    if pure_prob > best_p:\n        print(f\"  Pure: BULLISH - ML predicts price going up\")\n    else:\n        print(f\"  Pure: NEUTRAL - No strong upside signal\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10. Save Models"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save models and configuration\nimport os\nimport json\n\nos.makedirs('models', exist_ok=True)\n\n# Save models\njoblib.dump(guided_model, 'models/guided_model.pkl')\njoblib.dump(pure_model, 'models/pure_model.pkl')\njoblib.dump(scaler_guided, 'models/scaler_guided.pkl')\njoblib.dump(scaler_pure, 'models/scaler_pure.pkl')\n\n# Save configuration\nconfig = {\n    'features': FEATURES,\n    'best_guided_threshold': float(best_guided_thresh),\n    'best_pure_threshold': float(best_pure_thresh),\n    'ensemble_guided_threshold': float(best_g),\n    'ensemble_pure_threshold': float(best_p),\n    'lookahead_hours': LOOKAHEAD,\n    'target_pct': TARGET_PCT,\n    'guided_params': search.best_params_,\n    'pure_params': search_pure.best_params_\n}\n\nwith open('models/config.json', 'w') as f:\n    json.dump(config, f, indent=2, default=str)\n\nprint(\"Saved:\")\nprint(\"  - models/guided_model.pkl\")\nprint(\"  - models/pure_model.pkl\")\nprint(\"  - models/scaler_guided.pkl\")\nprint(\"  - models/scaler_pure.pkl\")\nprint(\"  - models/config.json\")\n\n# Download if on Colab\nif IN_COLAB:\n    from google.colab import files\n    import shutil\n    shutil.make_archive('models', 'zip', 'models')\n    files.download('models.zip')\n    print(\"\\nDownloaded models.zip\")"
  },
  {
   "cell_type": "code",
   "source": "# Save all results to file\nimport os\nfrom datetime import datetime\n\nos.makedirs('results', exist_ok=True)\ntimestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n\n# Compile all results\nresults_summary = {\n    'timestamp': timestamp,\n    'backtest_period': {\n        'start': str(test_data.index.min()),\n        'end': str(test_data.index.max())\n    },\n    'features_used': FEATURES,\n    'lookahead_hours': LOOKAHEAD,\n    'target_pct': TARGET_PCT,\n    \n    'guided_model': {\n        'best_threshold': float(best_guided_thresh),\n        'trades': int(guided_results['total_trades']),\n        'win_rate': float(guided_results['win_rate']),\n        'avg_return': float(guided_results['avg_return']),\n        'total_return': float(guided_results['total_return']),\n        'sharpe': float(guided_results['sharpe']),\n        'best_params': {k: str(v) for k, v in search.best_params_.items()}\n    },\n    \n    'pure_model': {\n        'best_threshold': float(best_pure_thresh),\n        'trades': int(pure_results['total_trades']),\n        'win_rate': float(pure_results['win_rate']),\n        'avg_return': float(pure_results['avg_return']),\n        'total_return': float(pure_results['total_return']),\n        'sharpe': float(pure_results['sharpe']),\n        'best_params': {k: str(v) for k, v in search_pure.best_params_.items()}\n    },\n    \n    'ensemble': {\n        'guided_threshold': float(best_g),\n        'pure_threshold': float(best_p),\n        'trades': int(ensemble_final['total_trades']),\n        'win_rate': float(ensemble_final['win_rate']),\n        'avg_return': float(ensemble_final['avg_return']),\n        'total_return': float(ensemble_final['total_return']),\n        'sharpe': float(ensemble_final['sharpe'])\n    },\n    \n    'all_ensemble_configs': ensemble_df.to_dict('records'),\n    'guided_threshold_sweep': guided_thresh_results.to_dict('records'),\n    'pure_threshold_sweep': pure_thresh_results.to_dict('records')\n}\n\n# Save JSON\nresults_file = f'results/backtest_{timestamp}.json'\nwith open(results_file, 'w') as f:\n    json.dump(results_summary, f, indent=2, default=str)\n\n# Save trades to CSV\nif len(guided_trades) > 0:\n    guided_trades.to_csv(f'results/guided_trades_{timestamp}.csv')\nif len(pure_trades) > 0:\n    pure_trades.to_csv(f'results/pure_trades_{timestamp}.csv')\nif len(ensemble_trades) > 0:\n    ensemble_trades.to_csv(f'results/ensemble_trades_{timestamp}.csv')\n\nprint(f\"Results saved to: {results_file}\")\nprint(f\"\\n{'='*60}\")\nprint(\"SUMMARY\")\nprint('='*60)\nprint(f\"\\nBacktest: {results_summary['backtest_period']['start']} to {results_summary['backtest_period']['end']}\")\nprint(f\"\\n{'Model':<12} {'Trades':>8} {'Win%':>8} {'Return%':>10} {'Sharpe':>8}\")\nprint('-'*50)\nprint(f\"{'Guided':<12} {guided_results['total_trades']:>8} {guided_results['win_rate']:>7.1f}% {guided_results['total_return']:>9.2f}% {guided_results['sharpe']:>8.2f}\")\nprint(f\"{'Pure':<12} {pure_results['total_trades']:>8} {pure_results['win_rate']:>7.1f}% {pure_results['total_return']:>9.2f}% {pure_results['sharpe']:>8.2f}\")\nprint(f\"{'Ensemble':<12} {ensemble_final['total_trades']:>8} {ensemble_final['win_rate']:>7.1f}% {ensemble_final['total_return']:>9.2f}% {ensemble_final['sharpe']:>8.2f}\")\n\n# Download if on Colab\nif IN_COLAB:\n    from google.colab import files\n    files.download(results_file)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}